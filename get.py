"""
ç¬¬äºŒé˜¶æ®µGNNæ‹“æ‰‘æå–å™¨
ä»ç¬¬ä¸€é˜¶æ®µå¯¼å‡ºçš„æ‹“æ‰‘ç»“æ„ä¸­æå–GNNå»ºæ¨¡æ‰€éœ€çš„å…³é”®ä¿¡æ¯
æ”¯æŒå¤šç§GNNæ¡†æ¶ï¼šPyTorch Geometric, DGL, NetworkX
"""

import json
import numpy as np
import torch
import networkx as nx
from typing import Dict, List, Tuple, Optional, Union
from dataclasses import dataclass, field
from pathlib import Path
import pickle
import warnings

try:
    import torch_geometric
    from torch_geometric.data import Data, HeteroData
    TORCH_GEOMETRIC_AVAILABLE = True
except ImportError:
    TORCH_GEOMETRIC_AVAILABLE = False
    warnings.warn("PyTorch Geometric not available. Some features will be disabled.")

try:
    import dgl
    DGL_AVAILABLE = True
except ImportError:
    DGL_AVAILABLE = False
    warnings.warn("DGL not available. Some features will be disabled.")

@dataclass
class GNNTopologyConfig:
    """GNNæ‹“æ‰‘æå–é…ç½®"""
    include_spatial_features: bool = True
    include_road_features: bool = True
    include_traffic_features: bool = True
    normalize_features: bool = True
    add_self_loops: bool = True
    directed_graph: bool = True
    max_edge_distance: float = 200.0  # æœ€å¤§è¾¹è¿æ¥è·ç¦»
    use_hierarchical_structure: bool = True  # æ˜¯å¦ä½¿ç”¨å±‚æ¬¡ç»“æ„
    
@dataclass
class NodeFeatures:
    """èŠ‚ç‚¹ç‰¹å¾æ•°æ®ç»“æ„"""
    node_id: str
    position: np.ndarray
    node_type: str  # 'endpoint', 'key_node', 'intersection'
    importance: float
    traffic_capacity: int
    road_class: str
    is_endpoint: bool
    path_memberships: List[str]
    spatial_features: np.ndarray = field(default_factory=lambda: np.array([]))
    
@dataclass
class EdgeFeatures:
    """è¾¹ç‰¹å¾æ•°æ®ç»“æ„"""
    source: str
    target: str
    path_length: float
    road_class: str
    curvature: float
    grade: float
    capacity: float
    bidirectional: bool = True

@dataclass
class GraphTopology:
    """å›¾æ‹“æ‰‘ç»“æ„"""
    nodes: Dict[str, NodeFeatures]
    edges: List[EdgeFeatures]
    adjacency_matrix: np.ndarray
    node_feature_matrix: np.ndarray
    edge_feature_matrix: np.ndarray
    node_to_index: Dict[str, int]
    index_to_node: Dict[int, str]

class Stage1TopologyExtractor:
    """ç¬¬ä¸€é˜¶æ®µæ‹“æ‰‘æå–å™¨"""
    
    def __init__(self, config: GNNTopologyConfig = None):
        self.config = config or GNNTopologyConfig()
        self.topology = None
        self.raw_data = None
        
    def load_stage1_data(self, json_file_path: str) -> Dict:
        """åŠ è½½ç¬¬ä¸€é˜¶æ®µå¯¼å‡ºæ•°æ®"""
        try:
            with open(json_file_path, 'r', encoding='utf-8') as f:
                self.raw_data = json.load(f)
            
            print(f"âœ… æˆåŠŸåŠ è½½ç¬¬ä¸€é˜¶æ®µæ•°æ®: {json_file_path}")
            print(f"ğŸ“Š æ•°æ®æ¦‚è§ˆ:")
            print(f"  - å…³é”®èŠ‚ç‚¹æ•°: {len(self.raw_data.get('key_nodes_info', {}))}")
            print(f"  - æ•´åˆè·¯å¾„æ•°: {len(self.raw_data.get('consolidated_paths_info', {}))}")
            print(f"  - èŠ‚ç‚¹å‡å°‘ç‡: {self.raw_data.get('enhanced_consolidation_stats', {}).get('node_reduction_ratio', 0):.1%}")
            
            return self.raw_data
            
        except Exception as e:
            raise RuntimeError(f"âŒ åŠ è½½ç¬¬ä¸€é˜¶æ®µæ•°æ®å¤±è´¥: {e}")
    
    def extract_topology(self) -> GraphTopology:
        """æå–å›¾æ‹“æ‰‘ç»“æ„"""
        if not self.raw_data:
            raise RuntimeError("è¯·å…ˆåŠ è½½ç¬¬ä¸€é˜¶æ®µæ•°æ®")
        
        print("ğŸ”„ å¼€å§‹æå–å›¾æ‹“æ‰‘ç»“æ„...")
        
        # æå–èŠ‚ç‚¹
        nodes = self._extract_nodes()
        print(f"ğŸ“ æå–èŠ‚ç‚¹å®Œæˆ: {len(nodes)}ä¸ªèŠ‚ç‚¹")
        
        # æå–è¾¹
        edges = self._extract_edges()
        print(f"ğŸ”— æå–è¾¹å®Œæˆ: {len(edges)}æ¡è¾¹")
        
        # æ„å»ºé‚»æ¥çŸ©é˜µå’Œç‰¹å¾çŸ©é˜µ
        node_to_index = {node_id: idx for idx, node_id in enumerate(nodes.keys())}
        index_to_node = {idx: node_id for node_id, idx in node_to_index.items()}
        
        adjacency_matrix = self._build_adjacency_matrix(nodes, edges, node_to_index)
        node_feature_matrix = self._build_node_feature_matrix(nodes, node_to_index)
        edge_feature_matrix = self._build_edge_feature_matrix(edges)
        
        self.topology = GraphTopology(
            nodes=nodes,
            edges=edges,
            adjacency_matrix=adjacency_matrix,
            node_feature_matrix=node_feature_matrix,
            edge_feature_matrix=edge_feature_matrix,
            node_to_index=node_to_index,
            index_to_node=index_to_node
        )
        
        print("âœ… å›¾æ‹“æ‰‘ç»“æ„æå–å®Œæˆ")
        return self.topology
    
    def _extract_nodes(self) -> Dict[str, NodeFeatures]:
        """æå–èŠ‚ç‚¹ä¿¡æ¯"""
        nodes = {}
        key_nodes_info = self.raw_data.get('key_nodes_info', {})
        
        for node_id, node_data in key_nodes_info.items():
            # åŸºç¡€ç‰¹å¾
            position = np.array(node_data['position'][:2])  # åªå–x,yåæ ‡
            
            # ç©ºé—´ç‰¹å¾
            spatial_features = []
            if self.config.include_spatial_features:
                # æ·»åŠ ç©ºé—´ç‰¹å¾ï¼šåæ ‡ã€è§’åº¦ç­‰
                spatial_features.extend([
                    position[0], position[1],  # x, yåæ ‡
                    node_data['position'][2] if len(node_data['position']) > 2 else 0.0,  # è§’åº¦æˆ–é«˜ç¨‹
                ])
            
            # é“è·¯ç‰¹å¾
            if self.config.include_road_features:
                road_class_encoding = self._encode_road_class(node_data.get('road_class', 'secondary'))
                spatial_features.extend(road_class_encoding)
            
            # äº¤é€šç‰¹å¾
            if self.config.include_traffic_features:
                spatial_features.extend([
                    node_data.get('importance', 1.0) / 10.0,  # å½’ä¸€åŒ–é‡è¦æ€§
                    node_data.get('traffic_capacity', 100) / 200.0,  # å½’ä¸€åŒ–å®¹é‡
                    len(node_data.get('path_memberships', [])) / 50.0,  # å½’ä¸€åŒ–è·¯å¾„æ•°
                ])
            
            nodes[node_id] = NodeFeatures(
                node_id=node_id,
                position=position,
                node_type=node_data.get('node_type', 'key_node'),
                importance=node_data.get('importance', 1.0),
                traffic_capacity=node_data.get('traffic_capacity', 100),
                road_class=node_data.get('road_class', 'secondary'),
                is_endpoint=node_data.get('is_endpoint', False),
                path_memberships=node_data.get('path_memberships', []),
                spatial_features=np.array(spatial_features)
            )
        
        return nodes
    
    def _extract_edges(self) -> List[EdgeFeatures]:
        """æå–è¾¹ä¿¡æ¯"""
        edges = []
        consolidated_paths = self.raw_data.get('consolidated_paths_info', {})
        key_nodes_info = self.raw_data.get('key_nodes_info', {})
        
        # ä»æ•´åˆè·¯å¾„ä¸­æå–è¾¹
        for path_id, path_info in consolidated_paths.items():
            key_nodes = path_info.get('key_nodes', [])
            
            for i in range(len(key_nodes) - 1):
                source_node = key_nodes[i]
                target_node = key_nodes[i + 1]
                
                # æ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦å­˜åœ¨
                if source_node not in key_nodes_info or target_node not in key_nodes_info:
                    continue
                
                # è®¡ç®—è¾¹ç‰¹å¾
                source_pos = np.array(key_nodes_info[source_node]['position'][:2])
                target_pos = np.array(key_nodes_info[target_node]['position'][:2])
                distance = np.linalg.norm(target_pos - source_pos)
                
                # è·³è¿‡è¿‡é•¿çš„è¾¹ï¼ˆå¯èƒ½æ˜¯é”™è¯¯è¿æ¥ï¼‰
                if distance > self.config.max_edge_distance:
                    continue
                
                edge = EdgeFeatures(
                    source=source_node,
                    target=target_node,
                    path_length=distance,
                    road_class=path_info.get('road_class', 'secondary'),
                    curvature=path_info.get('avg_curvature', 0.0),
                    grade=0.0,  # å¯ä»¥ä»path_infoä¸­æå–
                    capacity=self._get_road_capacity(path_info.get('road_class', 'secondary')),
                    bidirectional=True
                )
                edges.append(edge)
        
        # æ·»åŠ ç©ºé—´é‚»è¿‘è¾¹ï¼ˆç”¨äºå¢å¼ºè¿é€šæ€§ï¼‰
        edges.extend(self._add_spatial_proximity_edges(key_nodes_info))
        
        return edges
    
    def _add_spatial_proximity_edges(self, key_nodes_info: Dict) -> List[EdgeFeatures]:
        """æ·»åŠ ç©ºé—´é‚»è¿‘è¾¹"""
        proximity_edges = []
        nodes_list = list(key_nodes_info.items())
        
        for i, (node1_id, node1_data) in enumerate(nodes_list):
            pos1 = np.array(node1_data['position'][:2])
            
            for j, (node2_id, node2_data) in enumerate(nodes_list[i+1:], i+1):
                pos2 = np.array(node2_data['position'][:2])
                distance = np.linalg.norm(pos2 - pos1)
                
                # æ·»åŠ é‚»è¿‘èŠ‚ç‚¹é—´çš„è¾¹
                if distance < 50.0:  # 50ç±³å†…çš„èŠ‚ç‚¹
                    edge = EdgeFeatures(
                        source=node1_id,
                        target=node2_id,
                        path_length=distance,
                        road_class='auxiliary',
                        curvature=0.0,
                        grade=0.0,
                        capacity=50.0,
                        bidirectional=True
                    )
                    proximity_edges.append(edge)
        
        return proximity_edges
    
    def _build_adjacency_matrix(self, nodes: Dict, edges: List[EdgeFeatures], 
                               node_to_index: Dict[str, int]) -> np.ndarray:
        """æ„å»ºé‚»æ¥çŸ©é˜µ"""
        n_nodes = len(nodes)
        adj_matrix = np.zeros((n_nodes, n_nodes), dtype=np.float32)
        
        for edge in edges:
            if edge.source in node_to_index and edge.target in node_to_index:
                i = node_to_index[edge.source]
                j = node_to_index[edge.target]
                
                # ä½¿ç”¨è·ç¦»çš„å€’æ•°ä½œä¸ºæƒé‡
                weight = 1.0 / (edge.path_length + 1e-6)
                adj_matrix[i, j] = weight
                
                if edge.bidirectional:
                    adj_matrix[j, i] = weight
        
        # æ·»åŠ è‡ªç¯
        if self.config.add_self_loops:
            np.fill_diagonal(adj_matrix, 1.0)
        
        return adj_matrix
    
    def _build_node_feature_matrix(self, nodes: Dict, node_to_index: Dict[str, int]) -> np.ndarray:
        """æ„å»ºèŠ‚ç‚¹ç‰¹å¾çŸ©é˜µ"""
        n_nodes = len(nodes)
        
        # ç¡®å®šç‰¹å¾ç»´åº¦
        sample_features = next(iter(nodes.values())).spatial_features
        feature_dim = len(sample_features)
        
        feature_matrix = np.zeros((n_nodes, feature_dim), dtype=np.float32)
        
        for node_id, node in nodes.items():
            idx = node_to_index[node_id]
            feature_matrix[idx] = node.spatial_features
        
        # ç‰¹å¾å½’ä¸€åŒ–
        if self.config.normalize_features:
            feature_matrix = self._normalize_features(feature_matrix)
        
        return feature_matrix
    
    def _build_edge_feature_matrix(self, edges: List[EdgeFeatures]) -> np.ndarray:
        """æ„å»ºè¾¹ç‰¹å¾çŸ©é˜µ"""
        n_edges = len(edges)
        
        # è¾¹ç‰¹å¾ï¼š[è·¯å¾„é•¿åº¦, é“è·¯ç­‰çº§ç¼–ç , æ›²ç‡, å¡åº¦, å®¹é‡]
        edge_features = []
        
        for edge in edges:
            features = [
                edge.path_length / 100.0,  # å½’ä¸€åŒ–è·ç¦»
                *self._encode_road_class(edge.road_class),  # é“è·¯ç­‰çº§ç¼–ç 
                edge.curvature,
                edge.grade,
                edge.capacity / 200.0,  # å½’ä¸€åŒ–å®¹é‡
            ]
            edge_features.append(features)
        
        edge_matrix = np.array(edge_features, dtype=np.float32)
        
        if self.config.normalize_features:
            edge_matrix = self._normalize_features(edge_matrix)
        
        return edge_matrix
    
    def _encode_road_class(self, road_class: str) -> List[float]:
        """é“è·¯ç­‰çº§ç¼–ç """
        encoding_map = {
            'primary': [1.0, 0.0, 0.0],
            'secondary': [0.0, 1.0, 0.0],
            'auxiliary': [0.0, 0.0, 1.0],
        }
        return encoding_map.get(road_class, [0.0, 1.0, 0.0])
    
    def _get_road_capacity(self, road_class: str) -> float:
        """è·å–é“è·¯å®¹é‡"""
        capacity_map = {
            'primary': 200.0,
            'secondary': 100.0,
            'auxiliary': 50.0,
        }
        return capacity_map.get(road_class, 100.0)
    
    def _normalize_features(self, features: np.ndarray) -> np.ndarray:
        """ç‰¹å¾å½’ä¸€åŒ–"""
        # ä½¿ç”¨æ ‡å‡†åŒ–ï¼š(x - mean) / std
        mean = np.mean(features, axis=0)
        std = np.std(features, axis=0)
        std[std == 0] = 1.0  # é¿å…é™¤é›¶
        
        normalized = (features - mean) / std
        return normalized

class GNNDataConverter:
    """GNNæ•°æ®æ ¼å¼è½¬æ¢å™¨"""
    
    def __init__(self, topology: GraphTopology):
        self.topology = topology
    
    def to_pytorch_geometric(self) -> 'Data':
        """è½¬æ¢ä¸ºPyTorch Geometricæ ¼å¼"""
        if not TORCH_GEOMETRIC_AVAILABLE:
            raise RuntimeError("PyTorch Geometric not available")
        
        # æ„å»ºè¾¹ç´¢å¼•
        edge_index = []
        edge_attr = []
        
        for i, edge in enumerate(self.topology.edges):
            source_idx = self.topology.node_to_index[edge.source]
            target_idx = self.topology.node_to_index[edge.target]
            
            edge_index.append([source_idx, target_idx])
            edge_attr.append(self.topology.edge_feature_matrix[i])
            
            if edge.bidirectional:
                edge_index.append([target_idx, source_idx])
                edge_attr.append(self.topology.edge_feature_matrix[i])
        
        edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()
        edge_attr = torch.tensor(edge_attr, dtype=torch.float)
        
        # èŠ‚ç‚¹ç‰¹å¾
        x = torch.tensor(self.topology.node_feature_matrix, dtype=torch.float)
        
        # èŠ‚ç‚¹ä½ç½®
        pos = torch.tensor([
            node.position for node in self.topology.nodes.values()
        ], dtype=torch.float)
        
        data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, pos=pos)
        
        # æ·»åŠ èŠ‚ç‚¹ç±»å‹
        node_types = []
        for node in self.topology.nodes.values():
            if node.is_endpoint:
                node_types.append(0)  # ç«¯ç‚¹
            elif node.node_type == 'key_node':
                node_types.append(1)  # å…³é”®èŠ‚ç‚¹
            else:
                node_types.append(2)  # å…¶ä»–
        
        data.node_type = torch.tensor(node_types, dtype=torch.long)
        
        return data
    
    def to_dgl(self) -> 'dgl.DGLGraph':
        """è½¬æ¢ä¸ºDGLæ ¼å¼"""
        if not DGL_AVAILABLE:
            raise RuntimeError("DGL not available")
        
        # æ„å»ºè¾¹åˆ—è¡¨
        src_nodes = []
        dst_nodes = []
        
        for edge in self.topology.edges:
            source_idx = self.topology.node_to_index[edge.source]
            target_idx = self.topology.node_to_index[edge.target]
            
            src_nodes.append(source_idx)
            dst_nodes.append(target_idx)
            
            if edge.bidirectional:
                src_nodes.append(target_idx)
                dst_nodes.append(source_idx)
        
        # åˆ›å»ºå›¾
        g = dgl.graph((src_nodes, dst_nodes))
        
        # æ·»åŠ èŠ‚ç‚¹ç‰¹å¾
        g.ndata['feat'] = torch.tensor(self.topology.node_feature_matrix, dtype=torch.float)
        g.ndata['pos'] = torch.tensor([
            node.position for node in self.topology.nodes.values()
        ], dtype=torch.float)
        
        # æ·»åŠ è¾¹ç‰¹å¾
        edge_features = []
        for i, edge in enumerate(self.topology.edges):
            edge_features.append(self.topology.edge_feature_matrix[i])
            if edge.bidirectional:
                edge_features.append(self.topology.edge_feature_matrix[i])
        
        g.edata['feat'] = torch.tensor(edge_features, dtype=torch.float)
        
        return g
    
    def to_networkx(self) -> nx.Graph:
        """è½¬æ¢ä¸ºNetworkXæ ¼å¼"""
        if self.topology.config.directed_graph:
            G = nx.DiGraph()
        else:
            G = nx.Graph()
        
        # æ·»åŠ èŠ‚ç‚¹
        for node_id, node in self.topology.nodes.items():
            G.add_node(node_id, 
                      pos=node.position,
                      node_type=node.node_type,
                      importance=node.importance,
                      capacity=node.traffic_capacity,
                      is_endpoint=node.is_endpoint)
        
        # æ·»åŠ è¾¹
        for edge in self.topology.edges:
            G.add_edge(edge.source, edge.target,
                      weight=edge.path_length,
                      road_class=edge.road_class,
                      capacity=edge.capacity)
        
        return G

class MultiAgentEnvironmentExtractor:
    """å¤šæ™ºèƒ½ä½“ç¯å¢ƒæå–å™¨"""
    
    def __init__(self, topology: GraphTopology):
        self.topology = topology
    
    def extract_agent_config(self) -> Dict:
        """æå–æ™ºèƒ½ä½“é…ç½®"""
        # è¯†åˆ«è£…å¸ç‚¹å’Œåœè½¦åœº
        loading_points = []
        unloading_points = []
        parking_points = []
        
        for node_id, node in self.topology.nodes.items():
            if node.is_endpoint:
                if 'L' in node_id and 'to' in node_id:
                    loading_points.append(node_id)
                elif 'U' in node_id:
                    unloading_points.append(node_id)
                elif 'P' in node_id:
                    parking_points.append(node_id)
        
        return {
            'loading_points': loading_points,
            'unloading_points': unloading_points,
            'parking_points': parking_points,
            'total_nodes': len(self.topology.nodes),
            'total_edges': len(self.topology.edges),
            'max_agents': min(len(loading_points) * 2, 50),  # é™åˆ¶æ™ºèƒ½ä½“æ•°é‡
        }
    
    def extract_constraints(self) -> Dict:
        """æå–çº¦æŸæ¡ä»¶"""
        # ä»ç¬¬ä¸€é˜¶æ®µæ•°æ®ä¸­æå–åŠ¨åŠ›å­¦çº¦æŸ
        constraints = {
            'max_speed': 30.0,  # km/h
            'max_acceleration': 2.0,  # m/sÂ²
            'turning_radius': 15.0,  # m
            'max_grade': 0.15,  # 15%
            'vehicle_length': 12.0,  # m
            'safety_distance': 5.0,  # m
        }
        
        # èŠ‚ç‚¹å®¹é‡çº¦æŸ
        node_constraints = {}
        for node_id, node in self.topology.nodes.items():
            node_constraints[node_id] = {
                'max_occupancy': node.traffic_capacity // 10,  # åŒæ—¶å®¹çº³è½¦è¾†æ•°
                'service_time': 30.0 if node.is_endpoint else 5.0,  # æœåŠ¡æ—¶é—´ï¼ˆç§’ï¼‰
            }
        
        constraints['node_constraints'] = node_constraints
        return constraints

def main():
    """ä¸»å‡½æ•°ç¤ºä¾‹"""
    # é…ç½®æå–å™¨
    config = GNNTopologyConfig(
        include_spatial_features=True,
        include_road_features=True,
        include_traffic_features=True,
        normalize_features=True,
        add_self_loops=True,
        directed_graph=True
    )
    
    # åˆ›å»ºæå–å™¨
    extractor = Stage1TopologyExtractor(config)
    
    # åŠ è½½ç¬¬ä¸€é˜¶æ®µæ•°æ®
    try:
        extractor.load_stage1_data("Topu_Nanjing.json")
        
        # æå–æ‹“æ‰‘ç»“æ„
        topology = extractor.extract_topology()
        
        print(f"\nğŸ“Š æ‹“æ‰‘ç»“æ„ç»Ÿè®¡:")
        print(f"  - èŠ‚ç‚¹æ•°é‡: {len(topology.nodes)}")
        print(f"  - è¾¹æ•°é‡: {len(topology.edges)}")
        print(f"  - èŠ‚ç‚¹ç‰¹å¾ç»´åº¦: {topology.node_feature_matrix.shape[1]}")
        print(f"  - è¾¹ç‰¹å¾ç»´åº¦: {topology.edge_feature_matrix.shape[1]}")
        
        # è½¬æ¢ä¸ºä¸åŒæ ¼å¼
        converter = GNNDataConverter(topology)
        
        # PyTorch Geometricæ ¼å¼
        if TORCH_GEOMETRIC_AVAILABLE:
            pyg_data = converter.to_pytorch_geometric()
            print(f"\nğŸ”¥ PyTorch Geometricæ•°æ®:")
            print(f"  - èŠ‚ç‚¹ç‰¹å¾: {pyg_data.x.shape}")
            print(f"  - è¾¹ç´¢å¼•: {pyg_data.edge_index.shape}")
            print(f"  - è¾¹ç‰¹å¾: {pyg_data.edge_attr.shape}")
            
            # ä¿å­˜PyGæ•°æ®
            torch.save(pyg_data, "gnn_topology_pyg.pt")
            print("ğŸ’¾ PyTorch Geometricæ•°æ®å·²ä¿å­˜: gnn_topology_pyg.pt")
        
        # DGLæ ¼å¼
        if DGL_AVAILABLE:
            dgl_graph = converter.to_dgl()
            print(f"\nğŸ”¥ DGLæ•°æ®:")
            print(f"  - èŠ‚ç‚¹æ•°: {dgl_graph.num_nodes()}")
            print(f"  - è¾¹æ•°: {dgl_graph.num_edges()}")
            
            # ä¿å­˜DGLæ•°æ®
            dgl.save_graphs("gnn_topology_dgl.bin", [dgl_graph])
            print("ğŸ’¾ DGLæ•°æ®å·²ä¿å­˜: gnn_topology_dgl.bin")
        
        # NetworkXæ ¼å¼
        nx_graph = converter.to_networkx()
        print(f"\nğŸ”¥ NetworkXæ•°æ®:")
        print(f"  - èŠ‚ç‚¹æ•°: {nx_graph.number_of_nodes()}")
        print(f"  - è¾¹æ•°: {nx_graph.number_of_edges()}")
        
        # å¤šæ™ºèƒ½ä½“ç¯å¢ƒé…ç½®
        ma_extractor = MultiAgentEnvironmentExtractor(topology)
        agent_config = ma_extractor.extract_agent_config()
        constraints = ma_extractor.extract_constraints()
        
        print(f"\nğŸ¤– å¤šæ™ºèƒ½ä½“ç¯å¢ƒ:")
        print(f"  - è£…è½½ç‚¹: {len(agent_config['loading_points'])}")
        print(f"  - å¸è½½ç‚¹: {len(agent_config['unloading_points'])}")
        print(f"  - åœè½¦åœº: {len(agent_config['parking_points'])}")
        print(f"  - æœ€å¤§æ™ºèƒ½ä½“æ•°: {agent_config['max_agents']}")
        
        # ä¿å­˜å®Œæ•´é…ç½®
        full_config = {
            'topology_config': config.__dict__,
            'agent_config': agent_config,
            'constraints': constraints,
            'node_mapping': topology.node_to_index,
        }
        
        with open("stage2_gnn_config.json", 'w', encoding='utf-8') as f:
            json.dump(full_config, f, indent=2, ensure_ascii=False, default=str)
        
        print("\nâœ… ç¬¬äºŒé˜¶æ®µGNNé…ç½®å·²ä¿å­˜: stage2_gnn_config.json")
        print("ğŸš€ å‡†å¤‡å°±ç»ªï¼Œå¯ä»¥å¼€å§‹ç¬¬äºŒé˜¶æ®µGNNå»ºæ¨¡ï¼")
        
    except Exception as e:
        print(f"âŒ å¤„ç†å¤±è´¥: {e}")

if __name__ == "__main__":
    main()