"""
demo_MAGEC.py - åŸºäºç”Ÿæˆæ‹“æ‰‘ç»“æ„çš„MAGECè®­ç»ƒç³»ç»Ÿ
ä¸“æ³¨äºç¬¬äºŒé˜¶æ®µï¼šMAGECå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ è®­ç»ƒ

åŸºäºè®ºæ–‡: "Graph Neural Network-based Multi-agent Reinforcement Learning 
for Resilient Distributed Coordination of Multi-Robot Systems"

ğŸ¯ ä¸»è¦åŠŸèƒ½:
  - äº¤äº’å¼é€‰æ‹©ï¼šè½½å…¥ç¯å¢ƒ æˆ– è½½å…¥ç¬¬ä¸€é˜¶æ®µæ‹“æ‰‘JSON
  - å°†æ‹“æ‰‘ç»“æ„æ™ºèƒ½æ˜ å°„åˆ°è®­ç»ƒç¯å¢ƒ
  - ä¸“æ³¨äºMAGECç®—æ³•çš„è®­ç»ƒè¿‡ç¨‹
  - ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹ä¾›visualize.pyä½¿ç”¨

ğŸš€ ä½¿ç”¨æ–¹æ³•:
  python demo_MAGEC.py
  
ğŸ“‹ å·¥ä½œæµç¨‹:
  1. äº¤äº’å¼é€‰æ‹©æ•°æ®æºï¼ˆç¯å¢ƒæ–‡ä»¶ æˆ– æ‹“æ‰‘JSONï¼‰
  2. æ„å»ºMAGECè®­ç»ƒç¯å¢ƒ
  3. æ‰§è¡ŒMAGECè®­ç»ƒ
  4. ä¿å­˜è®­ç»ƒæ¨¡å‹å’Œç»“æœ
"""

import sys
import os
import json
import time
import random
import argparse
import numpy as np
import networkx as nx
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.nn import MessagePassing
from torch_geometric.data import Data, Batch
from torch_geometric.utils import add_self_loops
from typing import Dict, List, Tuple, Optional, Any
from pathlib import Path
from collections import defaultdict, deque
from tqdm import tqdm
import logging

# å¯¼å…¥ç¬¬ä¸€é˜¶æ®µçš„æ‹“æ‰‘æ„å»ºæ¨¡å—
try:
    from environment import OptimizedOpenPitMineEnv
    from optimized_backbone_network import OptimizedBackboneNetwork
    from optimized_planner_config import EnhancedPathPlannerWithConfig
    print("âœ… ç¬¬ä¸€é˜¶æ®µæ‹“æ‰‘æ„å»ºæ¨¡å—å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ ç¬¬ä¸€é˜¶æ®µæ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    print("âš ï¸ å°†ä½¿ç”¨ç®€åŒ–æ¨¡å¼")

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ============================================================================
# MAGECç½‘ç»œæ¶æ„ (åŸºäºè®ºæ–‡å®ç°)
# ============================================================================

class GraphSAGEConv(MessagePassing):
    """GraphSAGE with Edge Features (Algorithm 1 in paper)"""
    def __init__(self, in_channels: int, out_channels: int, edge_dim: int, 
                 dropout: float = 0.1, aggr: str = 'mean'):
        super().__init__(aggr=aggr)
        
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.edge_dim = edge_dim
        self.dropout = dropout
        
        # Weight matrices as in Algorithm 1
        self.lin_neighbor = nn.Linear(in_channels + edge_dim, out_channels)
        self.lin_self = nn.Linear(in_channels, out_channels)
        self.dropout_layer = nn.Dropout(dropout)
        
        self.reset_parameters()
    
    def reset_parameters(self):
        nn.init.xavier_uniform_(self.lin_neighbor.weight)
        nn.init.xavier_uniform_(self.lin_self.weight)
    
    def forward(self, x, edge_index, edge_attr=None):
        # Add self loops
        edge_index, edge_attr = add_self_loops(edge_index, edge_attr, 
                                               num_nodes=x.size(0), fill_value=0.0)
        
        # Propagate
        out = self.propagate(edge_index, x=x, edge_attr=edge_attr)
        
        # Self connection
        out = out + self.lin_self(x)
        
        # Normalization and activation
        out = F.normalize(out, p=2, dim=-1)
        out = F.relu(out)
        out = self.dropout_layer(out)
        
        return out
    
    def message(self, x_j, edge_attr):
        # Concatenate node and edge features (Line 6 in Algorithm 1)
        if edge_attr is None:
            edge_attr = torch.zeros(x_j.size(0), self.edge_dim, 
                                   device=x_j.device, dtype=x_j.dtype)
        
        # Ensure edge_attr has correct dimensions
        if edge_attr.size(-1) != self.edge_dim:
            if edge_attr.size(-1) < self.edge_dim:
                padding = torch.zeros(edge_attr.size(0), 
                                     self.edge_dim - edge_attr.size(-1),
                                     device=edge_attr.device, dtype=edge_attr.dtype)
                edge_attr = torch.cat([edge_attr, padding], dim=-1)
            else:
                edge_attr = edge_attr[:, :self.edge_dim]
        
        # Concatenate and transform
        augmented = torch.cat([x_j, edge_attr], dim=-1)
        return self.lin_neighbor(augmented)

class MAGECActor(nn.Module):
    """MAGEC Actor Network with Neighbor Scoring (è®ºæ–‡Figure 1)"""
    def __init__(self, node_features: int, edge_features: int, hidden_size: int,
                 num_layers: int, max_neighbors: int, dropout: float = 0.1,
                 use_skip_connections: bool = True):
        super().__init__()
        
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        self.max_neighbors = max_neighbors
        self.use_skip_connections = use_skip_connections
        
        # Input projection
        self.input_projection = nn.Linear(node_features, hidden_size)
        
        # GNN layers (k-convolution as mentioned in paper)
        self.gnn_layers = nn.ModuleList()
        for _ in range(num_layers):
            self.gnn_layers.append(
                GraphSAGEConv(hidden_size, hidden_size, edge_features, dropout)
            )
        
        # Jumping knowledge (skip connections)
        if use_skip_connections:
            self.jump_connection = nn.Linear(hidden_size * num_layers, hidden_size)
        
        # Neighbor scoring mechanism (Section IV-D)
        self.neighbor_scorer = nn.Sequential(
            nn.Linear(hidden_size, hidden_size // 2),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_size // 2, 1)
        )
        
        # Action selector (selection MLP)
        self.action_selector = nn.Sequential(
            nn.Linear(max_neighbors, hidden_size // 2),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_size // 2, max_neighbors)
        )
        
        self.apply(self._init_weights)
    
    def _init_weights(self, module):
        if isinstance(module, nn.Linear):
            nn.init.xavier_uniform_(module.weight, gain=0.1)
            if module.bias is not None:
                nn.init.zeros_(module.bias)
    
    def forward(self, batch_data, agent_indices=None):
        """Forward pass implementing the neighbor scoring mechanism"""
        device = next(self.parameters()).device
        
        if not isinstance(batch_data, list):
            batch_data = [batch_data]
        
        batch_action_logits = []
        
        for i, data in enumerate(batch_data):
            try:
                # Validate data
                if not hasattr(data, 'x') or data.x is None or data.x.size(0) == 0:
                    # Create dummy output
                    action_logits = torch.zeros(self.max_neighbors, device=device)
                    batch_action_logits.append(action_logits)
                    continue
                
                # Move to device
                x = data.x.to(device)
                edge_index = data.edge_index.to(device)
                edge_attr = data.edge_attr.to(device) if hasattr(data, 'edge_attr') else None
                
                # Get agent position
                agent_idx = agent_indices[i] if agent_indices and i < len(agent_indices) else 0
                agent_idx = min(agent_idx, x.size(0) - 1)
                
                # Input projection
                h = self.input_projection(x)
                
                # GNN layers with skip connections
                layer_outputs = []
                for gnn_layer in self.gnn_layers:
                    h = gnn_layer(h, edge_index, edge_attr)
                    if self.use_skip_connections:
                        layer_outputs.append(h)
                
                # Jumping knowledge
                if self.use_skip_connections and len(layer_outputs) > 1:
                    h = torch.cat(layer_outputs, dim=-1)
                    h = self.jump_connection(h)
                
                # Neighbor scoring
                action_logits = self._compute_action_logits(h, agent_idx)
                batch_action_logits.append(action_logits)
                
            except Exception as e:
                logger.warning(f"Forward pass failed for sample {i}: {e}")
                action_logits = torch.zeros(self.max_neighbors, device=device)
                batch_action_logits.append(action_logits)
        
        return torch.stack(batch_action_logits)
    
    def _compute_action_logits(self, node_embeddings, agent_idx):
        """Implement neighbor scoring mechanism (Section IV-D)"""
        device = node_embeddings.device
        num_nodes = node_embeddings.size(0)
        
        # Score all potential neighbors
        neighbor_scores = []
        for i in range(self.max_neighbors):
            if i < num_nodes and i != agent_idx:
                # Score this neighbor
                neighbor_embedding = node_embeddings[i]
                score = self.neighbor_scorer(neighbor_embedding).squeeze()
                neighbor_scores.append(score)
            else:
                # Invalid neighbor (padding)
                score = torch.tensor(-10.0, device=device)
                neighbor_scores.append(score)
        
        # Convert to tensor and apply action selector
        scores_tensor = torch.stack(neighbor_scores)
        action_logits = self.action_selector(scores_tensor.unsqueeze(0)).squeeze(0)
        
        return action_logits

class MAGECCritic(nn.Module):
    """Simple MLP Critic for centralized training (CTDE) - Section IV-A"""
    def __init__(self, global_state_size: int, hidden_size: int = 512):
        super().__init__()
        
        self.network = nn.Sequential(
            nn.Linear(global_state_size, hidden_size),
            nn.ReLU(),
            nn.LayerNorm(hidden_size),
            nn.Dropout(0.1),
            nn.Linear(hidden_size, hidden_size),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_size, hidden_size // 2),
            nn.ReLU(),
            nn.Linear(hidden_size // 2, 1)
        )
        
        self.apply(self._init_weights)
    
    def _init_weights(self, module):
        if isinstance(module, nn.Linear):
            nn.init.xavier_uniform_(module.weight)
            if module.bias is not None:
                nn.init.zeros_(module.bias)
    
    def forward(self, global_state):
        if global_state.dim() == 1:
            global_state = global_state.unsqueeze(0)
        return self.network(global_state)

# ============================================================================
# æ‹“æ‰‘åˆ°MAGECç¯å¢ƒæ˜ å°„å™¨
# ============================================================================

class TopologyToMAGECMapper:
    """å°†ç¬¬ä¸€é˜¶æ®µæ‹“æ‰‘ç»“æ„æ˜ å°„åˆ°MAGECè®­ç»ƒç¯å¢ƒ"""
    
    def __init__(self):
        self.topology_data = None
        self.magec_graph = None
        self.node_features = {}
        self.edge_features = {}
        self.position_mapping = {}
        self.special_points = {}
    
    def load_topology_from_json(self, json_path: str) -> bool:
        """ä»JSONæ–‡ä»¶åŠ è½½æ‹“æ‰‘æ•°æ®"""
        try:
            with open(json_path, 'r', encoding='utf-8') as f:
                self.topology_data = json.load(f)
            
            # éªŒè¯JSONæ ¼å¼
            if not self._validate_topology_json():
                return False
            
            print(f"âœ… æ‹“æ‰‘JSONåŠ è½½æˆåŠŸ: {json_path}")
            return True
            
        except Exception as e:
            print(f"âŒ æ‹“æ‰‘JSONåŠ è½½å¤±è´¥: {e}")
            return False
    
    def _validate_topology_json(self) -> bool:
        """éªŒè¯æ‹“æ‰‘JSONæ ¼å¼"""
        required_fields = ['system', 'stage', 'ready_for_stage2']
        if not all(field in self.topology_data for field in required_fields):
            print("âŒ JSONç¼ºå°‘å¿…è¦å­—æ®µ")
            return False
        
        if not self.topology_data.get('ready_for_stage2', False):
            print("âŒ æ‹“æ‰‘æœªå®Œæˆç¬¬ä¸€é˜¶æ®µæ„å»º")
            return False
        
        return True
    
    def create_magec_environment(self, num_agents: int = 4) -> Dict:
        """åˆ›å»ºMAGECè®­ç»ƒç¯å¢ƒ"""
        print("ğŸ”„ å°†æ‹“æ‰‘ç»“æ„æ˜ å°„åˆ°MAGECç¯å¢ƒ...")
        
        # æ„å»ºå›¾ç»“æ„
        self.magec_graph = nx.Graph()
        
        # ä»æ‹“æ‰‘æ•°æ®æå–å…³é”®ä¿¡æ¯
        if 'key_nodes_info' in self.topology_data:
            self._build_from_key_nodes()
        elif 'construction_stats' in self.topology_data:
            self._build_from_construction_stats()
        else:
            print("âš ï¸ ä½¿ç”¨é»˜è®¤å›¾ç»“æ„")
            self._build_default_graph()
        
        # ç¡®ä¿å›¾è¿é€šæ€§
        self._ensure_connectivity()
        
        # é™åˆ¶æ™ºèƒ½ä½“æ•°é‡
        num_agents = min(num_agents, self.magec_graph.number_of_nodes())
        
        # æ„å»ºç¯å¢ƒé…ç½®
        env_config = {
            'graph': self.magec_graph,
            'node_features': self.node_features,
            'edge_features': self.edge_features,
            'position_mapping': self.position_mapping,
            'special_points': self.special_points,
            'num_agents': num_agents,
            'max_neighbors': self._calculate_max_neighbors()
        }
        
        print(f"âœ… MAGECç¯å¢ƒåˆ›å»ºå®Œæˆ:")
        print(f"   èŠ‚ç‚¹æ•°: {self.magec_graph.number_of_nodes()}")
        print(f"   è¾¹æ•°: {self.magec_graph.number_of_edges()}")
        print(f"   æ™ºèƒ½ä½“æ•°: {num_agents}")
        print(f"   æœ€å¤§é‚»å±…æ•°: {env_config['max_neighbors']}")
        
        return env_config
    
    def _build_from_key_nodes(self):
        """ä»å…³é”®èŠ‚ç‚¹ä¿¡æ¯æ„å»ºå›¾"""
        print("ä½¿ç”¨å…³é”®èŠ‚ç‚¹ä¿¡æ¯æ„å»ºå›¾...")
        
        key_nodes_info = self.topology_data['key_nodes_info']
        consolidated_paths_info = self.topology_data.get('consolidated_paths_info', {})
        
        # æ·»åŠ èŠ‚ç‚¹
        node_id_mapping = {}
        for i, (node_id, node_info) in enumerate(key_nodes_info.items()):
            pos = node_info['position'][:2]  # åªå–x,yåæ ‡
            
            self.magec_graph.add_node(i, pos=pos)
            node_id_mapping[node_id] = i
            self.position_mapping[i] = pos
            
            # èŠ‚ç‚¹ç‰¹å¾
            self.node_features[i] = {
                'encoded_type': 2.0 if node_info.get('is_endpoint', False) else 1.0,
                'idleness': 0.0,
                'degree': 0,
                'importance': node_info.get('importance', 1.0)
            }
        
        # æ·»åŠ è¾¹
        for path_id, path_info in consolidated_paths_info.items():
            key_nodes = path_info.get('key_nodes', [])
            if len(key_nodes) >= 2:
                for i in range(len(key_nodes) - 1):
                    node1_id = key_nodes[i]
                    node2_id = key_nodes[i + 1]
                    
                    if node1_id in node_id_mapping and node2_id in node_id_mapping:
                        idx1 = node_id_mapping[node1_id]
                        idx2 = node_id_mapping[node2_id]
                        
                        if not self.magec_graph.has_edge(idx1, idx2):
                            # è®¡ç®—è¾¹æƒé‡
                            pos1 = self.position_mapping[idx1]
                            pos2 = self.position_mapping[idx2]
                            distance = np.linalg.norm(np.array(pos1) - np.array(pos2))
                            
                            self.magec_graph.add_edge(idx1, idx2, weight=distance)
                            
                            # è¾¹ç‰¹å¾
                            self.edge_features[(idx1, idx2)] = {
                                'distance': distance,
                                'normalized_distance': min(distance / 50.0, 1.0),
                                'edge_id': len(self.edge_features) / 100.0
                            }
    
    def _build_from_construction_stats(self):
        """ä»æ„å»ºç»Ÿè®¡ä¿¡æ¯æ„å»ºå›¾"""
        print("ä½¿ç”¨æ„å»ºç»Ÿè®¡ä¿¡æ¯æ„å»ºå›¾...")
        
        construction_stats = self.topology_data['construction_stats']
        paths_count = construction_stats.get('paths_generated', 6)
        
        # åˆ›å»ºç®€å•çš„å›¾ç»“æ„
        num_nodes = paths_count * 3  # æ¯æ¡è·¯å¾„3ä¸ªèŠ‚ç‚¹
        
        for i in range(num_nodes):
            # ç”Ÿæˆåˆç†çš„èŠ‚ç‚¹ä½ç½®
            angle = 2 * np.pi * i / num_nodes
            radius = 30 + 20 * (i % 3)  # åˆ†å±‚å¸ƒå±€
            x = radius * np.cos(angle)
            y = radius * np.sin(angle)
            
            self.magec_graph.add_node(i, pos=(x, y))
            self.position_mapping[i] = (x, y)
            
            # èŠ‚ç‚¹ç‰¹å¾
            self.node_features[i] = {
                'encoded_type': 1.0,
                'idleness': 0.0,
                'degree': 0,
                'importance': 1.0
            }
        
        # è¿æ¥é‚»è¿‘èŠ‚ç‚¹
        for i in range(num_nodes):
            for j in range(i + 1, num_nodes):
                distance = np.linalg.norm(
                    np.array(self.position_mapping[i]) - np.array(self.position_mapping[j])
                )
                
                if distance < 40:  # è¿æ¥è·ç¦»é˜ˆå€¼
                    self.magec_graph.add_edge(i, j, weight=distance)
                    
                    # è¾¹ç‰¹å¾
                    self.edge_features[(i, j)] = {
                        'distance': distance,
                        'normalized_distance': distance / 40.0,
                        'edge_id': len(self.edge_features) / 100.0
                    }
    
    def _build_default_graph(self):
        """æ„å»ºé»˜è®¤å›¾ç»“æ„"""
        print("æ„å»ºé»˜è®¤milwaukeeå›¾...")
        
        # Milwaukee graph topology
        edges = [
            (0, 1), (0, 2), (1, 3), (2, 4), (3, 5), (4, 5),
            (5, 6), (6, 7), (6, 8), (7, 9), (8, 10), (9, 11),
            (10, 11), (11, 12), (12, 13), (12, 14), (13, 15),
            (14, 16), (15, 17), (16, 18), (17, 19), (18, 19),
            (1, 4), (3, 6), (5, 8), (7, 10), (9, 12), (11, 14),
            (13, 16), (15, 18), (2, 7), (4, 9)
        ]
        
        num_nodes = 20
        
        # ä½¿ç”¨spring layoutç”Ÿæˆä½ç½®
        temp_graph = nx.Graph()
        temp_graph.add_nodes_from(range(num_nodes))
        temp_graph.add_edges_from(edges)
        pos = nx.spring_layout(temp_graph, seed=42, k=3, iterations=50)
        
        # å»ºç«‹å›¾
        for i in range(num_nodes):
            position = (pos[i][0] * 100, pos[i][1] * 100)  # æ”¾å¤§åæ ‡
            self.magec_graph.add_node(i, pos=position)
            self.position_mapping[i] = position
            
            # èŠ‚ç‚¹ç‰¹å¾
            self.node_features[i] = {
                'encoded_type': 1.0,
                'idleness': 0.0,
                'degree': 0,
                'importance': 1.0
            }
        
        # æ·»åŠ è¾¹
        for i, j in edges:
            pos1 = self.position_mapping[i]
            pos2 = self.position_mapping[j]
            distance = np.linalg.norm(np.array(pos1) - np.array(pos2))
            
            self.magec_graph.add_edge(i, j, weight=distance)
            
            # è¾¹ç‰¹å¾
            self.edge_features[(i, j)] = {
                'distance': distance,
                'normalized_distance': min(distance / 50.0, 1.0),
                'edge_id': len(self.edge_features) / 100.0
            }
    
    def _ensure_connectivity(self):
        """ç¡®ä¿å›¾è¿é€šæ€§"""
        if not nx.is_connected(self.magec_graph):
            print("ä¿®å¤å›¾è¿é€šæ€§...")
            components = list(nx.connected_components(self.magec_graph))
            
            for i in range(len(components) - 1):
                # è¿æ¥æœ€è¿‘çš„èŠ‚ç‚¹å¯¹
                comp1 = list(components[i])
                comp2 = list(components[i + 1])
                
                min_dist = float('inf')
                best_pair = None
                
                for n1 in comp1:
                    for n2 in comp2:
                        pos1 = self.position_mapping[n1]
                        pos2 = self.position_mapping[n2]
                        dist = np.linalg.norm(np.array(pos1) - np.array(pos2))
                        
                        if dist < min_dist:
                            min_dist = dist
                            best_pair = (n1, n2)
                
                if best_pair:
                    n1, n2 = best_pair
                    self.magec_graph.add_edge(n1, n2, weight=min_dist)
                    
                    self.edge_features[(n1, n2)] = {
                        'distance': min_dist,
                        'normalized_distance': min(min_dist / 50.0, 1.0),
                        'edge_id': len(self.edge_features) / 100.0
                    }
    
    def _calculate_max_neighbors(self) -> int:
        """è®¡ç®—æœ€å¤§é‚»å±…æ•°"""
        if self.magec_graph.number_of_nodes() == 0:
            return 15
        
        max_degree = max(dict(self.magec_graph.degree()).values())
        return min(max_degree, 15)
    
    def visualize_mapped_topology(self, save_path: str = None):
        """å¯è§†åŒ–æ˜ å°„åçš„æ‹“æ‰‘ç»“æ„"""
        plt.figure(figsize=(12, 10))
        
        pos = self.position_mapping
        
        # ç»˜åˆ¶è¾¹
        nx.draw_networkx_edges(self.magec_graph, pos, alpha=0.5, width=2, edge_color='gray')
        
        # ç»˜åˆ¶èŠ‚ç‚¹
        node_colors = []
        for node in self.magec_graph.nodes():
            importance = self.node_features[node].get('importance', 1.0)
            if importance > 1.5:
                node_colors.append('red')  # é‡è¦èŠ‚ç‚¹
            else:
                node_colors.append('lightblue')  # æ™®é€šèŠ‚ç‚¹
        
        nx.draw_networkx_nodes(self.magec_graph, pos, node_color=node_colors, 
                              node_size=300, alpha=0.8)
        
        # èŠ‚ç‚¹æ ‡ç­¾
        nx.draw_networkx_labels(self.magec_graph, pos, font_size=10, font_weight='bold')
        
        plt.title('æ‹“æ‰‘ç»“æ„æ˜ å°„åˆ°MAGECç¯å¢ƒ', fontsize=16, fontweight='bold')
        plt.axis('equal')
        plt.grid(True, alpha=0.3)
        
        # æ·»åŠ å›¾ä¾‹
        import matplotlib.patches as patches
        legend_elements = [
            patches.Patch(color='red', label='é‡è¦èŠ‚ç‚¹'),
            patches.Patch(color='lightblue', label='æ™®é€šèŠ‚ç‚¹'),
            patches.Patch(color='gray', label='è¿æ¥è¾¹')
        ]
        plt.legend(handles=legend_elements, loc='upper right')
        
        if save_path:
            plt.savefig(save_path, dpi=150, bbox_inches='tight')
            print(f"âœ… æ‹“æ‰‘æ˜ å°„å›¾å·²ä¿å­˜: {save_path}")
        else:
            plt.show()
        
        plt.close()

# ============================================================================
# MAGECè®­ç»ƒç¯å¢ƒ
# ============================================================================

class MAGECTrainingEnvironment:
    """åŸºäºæ‹“æ‰‘æ˜ å°„çš„MAGECè®­ç»ƒç¯å¢ƒ"""
    
    def __init__(self, env_config: Dict):
        self.graph = env_config['graph']
        self.node_features = env_config['node_features']
        self.edge_features = env_config['edge_features']
        self.position_mapping = env_config['position_mapping']
        self.num_agents = env_config['num_agents']
        self.max_neighbors = env_config['max_neighbors']
        
        self.num_nodes = self.graph.number_of_nodes()
        self.current_step = 0
        self.max_cycles = 200
        
        # é‚»å±…å­—å…¸
        self.neighbor_dict = {}
        for node in self.graph.nodes():
            self.neighbor_dict[node] = list(self.graph.neighbors(node))
        
        # åˆå§‹åŒ–çŠ¶æ€
        self.agent_positions = []
        self.node_idleness = {}
        self.last_visit_time = {}
        
        self.reset()
    
    def reset(self):
        """é‡ç½®ç¯å¢ƒ"""
        # éšæœºåˆ†é…æ™ºèƒ½ä½“åˆå§‹ä½ç½®
        nodes = list(self.graph.nodes())
        self.agent_positions = random.sample(nodes, min(self.num_agents, len(nodes)))
        
        # åˆå§‹åŒ–èŠ‚ç‚¹é—²ç½®æ—¶é—´
        for node in self.graph.nodes():
            self.node_idleness[node] = 0
            self.last_visit_time[node] = -1
        
        # æ ‡è®°åˆå§‹ä½ç½®ä¸ºå·²è®¿é—®
        for pos in self.agent_positions:
            self.last_visit_time[pos] = 0
        
        self.current_step = 0
        
        return self.get_observations()
    
    def get_observations(self):
        """è·å–è§‚å¯Ÿ"""
        observations = []
        
        for agent_id in range(self.num_agents):
            obs = self._get_agent_observation(agent_id)
            observations.append(obs)
        
        return observations
    
    def _get_agent_observation(self, agent_id: int):
        """è·å–æ™ºèƒ½ä½“è§‚å¯Ÿ"""
        agent_pos = self.agent_positions[agent_id]
        
        # è·å–kè·³é‚»å±…
        observable_nodes = self._get_k_hop_neighbors(agent_pos, k=3)
        
        # æ„å»ºèŠ‚ç‚¹ç‰¹å¾
        node_features = []
        node_mapping = {}
        
        for i, node in enumerate(observable_nodes):
            node_mapping[node] = i
            
            # åŸºç¡€ç‰¹å¾
            base_features = self.node_features.get(node, {})
            
            # æ™ºèƒ½ä½“å­˜åœ¨
            has_agent = float(node in self.agent_positions)
            
            # å½’ä¸€åŒ–é—²ç½®æ—¶é—´
            idleness = self.node_idleness[node] / max(self.current_step + 1, 1)
            idleness = np.clip(idleness, 0.0, 1.0)
            
            features = [
                has_agent,
                idleness,
                base_features.get('degree', 0.0),
                base_features.get('encoded_type', 1.0)
            ]
            node_features.append(features)
        
        # æ„å»ºè¾¹ç´¢å¼•å’Œç‰¹å¾
        edge_index = []
        edge_attr = []
        
        for edge in self.graph.edges():
            u, v = edge
            if u in node_mapping and v in node_mapping:
                i, j = node_mapping[u], node_mapping[v]
                edge_index.append([i, j])
                edge_index.append([j, i])  # åŒå‘
                
                # è¾¹ç‰¹å¾
                edge_key = (u, v) if (u, v) in self.edge_features else (v, u)
                if edge_key in self.edge_features:
                    edge_data = self.edge_features[edge_key]
                    attr = [
                        edge_data.get('normalized_distance', 0.5),
                        edge_data.get('edge_id', 0.0)
                    ]
                else:
                    attr = [0.5, 0.0]
                
                edge_attr.append(attr)
                edge_attr.append(attr)
        
        if not edge_index:
            edge_index = [[0, 0]]
            edge_attr = [[0.0, 0.0]]
        
        agent_obs_pos = node_mapping.get(agent_pos, 0)
        
        return Data(
            x=torch.tensor(node_features, dtype=torch.float32),
            edge_index=torch.tensor(edge_index, dtype=torch.long).T.contiguous(),
            edge_attr=torch.tensor(edge_attr, dtype=torch.float32),
            agent_pos=torch.tensor([agent_obs_pos], dtype=torch.long),
            num_nodes=len(observable_nodes)
        )
    
    def _get_k_hop_neighbors(self, start_node: int, k: int) -> List[int]:
        """è·å–kè·³é‚»å±…"""
        visited = set()
        current_level = {start_node}
        
        for _ in range(k):
            next_level = set()
            for node in current_level:
                if node not in visited:
                    visited.add(node)
                    next_level.update(self.graph.neighbors(node))
            current_level = next_level - visited
            
            if not current_level:
                break
        
        return list(visited)
    
    def step(self, actions):
        """æ‰§è¡Œä¸€æ­¥"""
        if not isinstance(actions, (list, np.ndarray)):
            actions = [actions]
        
        actions = list(actions)[:self.num_agents]
        while len(actions) < self.num_agents:
            actions.append(0)
        
        rewards = []
        
        for agent_id, action in enumerate(actions):
            reward = self._execute_agent_action(agent_id, action)
            rewards.append(reward)
        
        self.current_step += 1
        self._update_idleness()
        
        done = self.current_step >= self.max_cycles
        
        # ç»ˆç«¯å¥–åŠ±
        if done:
            avg_idleness = np.mean(list(self.node_idleness.values()))
            terminal_reward = -avg_idleness * 0.5
            rewards = [r + terminal_reward for r in rewards]
        
        return self.get_observations(), rewards, done
    
    def _execute_agent_action(self, agent_id: int, action: int) -> float:
        """æ‰§è¡Œæ™ºèƒ½ä½“åŠ¨ä½œ"""
        agent_pos = self.agent_positions[agent_id]
        neighbors = self.neighbor_dict.get(agent_pos, [])
        
        if 0 <= action < len(neighbors):
            target_node = neighbors[action]
            
            # é¿å…å†²çª
            if target_node in self.agent_positions:
                return -0.1
            
            # ç§»åŠ¨
            self.agent_positions[agent_id] = target_node
            self.last_visit_time[target_node] = self.current_step
            
            # å¥–åŠ±è®¡ç®—
            old_idleness = self.node_idleness[target_node]
            avg_idleness = max(np.mean(list(self.node_idleness.values())), 1e-6)
            
            return (old_idleness + 1) / (avg_idleness + 1)
        else:
            return -0.05
    
    def _update_idleness(self):
        """æ›´æ–°èŠ‚ç‚¹é—²ç½®æ—¶é—´"""
        for node in self.graph.nodes():
            if self.last_visit_time[node] >= 0:
                self.node_idleness[node] = self.current_step - self.last_visit_time[node]
            else:
                self.node_idleness[node] = self.current_step

# ============================================================================
# MAGECè®­ç»ƒå™¨
# ============================================================================

class MAGECTrainer:
    """MAGECè®­ç»ƒå™¨ - MAPPOç®—æ³•"""
    
    def __init__(self, actor, critic, config, device='cpu'):
        self.actor = actor
        self.critic = critic
        self.config = config
        self.device = device
        
        # PPOå‚æ•°
        self.clip_param = config['training']['clip_param']
        self.value_loss_coef = config['training']['value_loss_coef']
        self.entropy_coef = config['training']['entropy_coef']
        self.max_grad_norm = config['training']['max_grad_norm']
        
        # ä¼˜åŒ–å™¨
        self.actor_optimizer = torch.optim.Adam(
            actor.parameters(), lr=config['training']['lr']
        )
        self.critic_optimizer = torch.optim.Adam(
            critic.parameters(), lr=config['training']['lr']
        )
        
        # ç»éªŒç¼“å†²
        self.reset_buffer()
    
    def reset_buffer(self):
        """é‡ç½®ç»éªŒç¼“å†²"""
        self.states = []
        self.actions = []
        self.rewards = []
        self.log_probs = []
        self.values = []
        self.dones = []
        self.observations = []
    
    def select_actions(self, observations, deterministic=False):
        """é€‰æ‹©åŠ¨ä½œ"""
        self.actor.eval()
        
        with torch.no_grad():
            # è·å–æ™ºèƒ½ä½“ä½ç½®
            agent_indices = []
            for obs in observations:
                if hasattr(obs, 'agent_pos'):
                    agent_indices.append(obs.agent_pos.item())
                else:
                    agent_indices.append(0)
            
            # å‰å‘ä¼ æ’­
            action_logits = self.actor(observations, agent_indices)
            
            actions = []
            log_probs = []
            entropies = []
            
            for i in range(len(observations)):
                logits = action_logits[i]
                probs = F.softmax(logits, dim=-1)
                probs = torch.clamp(probs, 1e-8, 1.0 - 1e-8)
                dist = torch.distributions.Categorical(probs)
                
                if deterministic:
                    action = torch.argmax(probs)
                else:
                    action = dist.sample()
                
                actions.append(action.item())
                log_probs.append(dist.log_prob(action).item())
                entropies.append(dist.entropy().item())
            
            return np.array(actions), np.array(log_probs), np.array(entropies)
    
    def get_value(self, global_state):
        """è·å–ä»·å€¼ä¼°è®¡"""
        self.critic.eval()
        with torch.no_grad():
            return self.critic(global_state).item()
    
    def store_transition(self, observations, global_state, actions, rewards, 
                        log_probs, values, dones):
        """å­˜å‚¨è½¬æ¢"""
        self.observations.append(observations)
        self.states.append(global_state)
        self.actions.append(actions)
        self.rewards.append(rewards)
        self.log_probs.append(log_probs)
        self.values.append(values)
        self.dones.append(dones)
    
    def update(self):
        """ä½¿ç”¨PPOæ›´æ–°ç½‘ç»œ"""
        if len(self.rewards) == 0:
            return {'actor_loss': 0.0, 'critic_loss': 0.0, 'entropy': 0.0}
        
        # è®¡ç®—å›æŠ¥å’Œä¼˜åŠ¿
        returns, advantages = self._compute_gae()
        
        # è½¬æ¢ä¸ºå¼ é‡
        states = torch.stack([s for s in self.states]).to(self.device)
        actions = torch.tensor([a[0] if len(a) > 0 else 0 for a in self.actions], 
                              dtype=torch.long).to(self.device)
        old_log_probs = torch.tensor([lp[0] if len(lp) > 0 else 0.0 for lp in self.log_probs], 
                                    dtype=torch.float32).to(self.device)
        returns = torch.tensor(returns, dtype=torch.float32).to(self.device)
        advantages = torch.tensor(advantages, dtype=torch.float32).to(self.device)
        
        # æ ‡å‡†åŒ–ä¼˜åŠ¿
        if advantages.std() > 1e-8:
            advantages = (advantages - advantages.mean()) / (advantages.std() + 1e-8)
        
        # PPOæ›´æ–°
        total_actor_loss = 0
        total_critic_loss = 0
        total_entropy = 0
        
        for epoch in range(self.config['training']['ppo_epochs']):
            # é‡æ–°è®¡ç®—åŠ¨ä½œæ¦‚ç‡
            new_log_probs, entropies = self._compute_action_probs(actions)
            
            if new_log_probs is not None:
                # PPOæŸå¤±
                ratio = torch.exp(new_log_probs - old_log_probs)
                surr1 = ratio * advantages
                surr2 = torch.clamp(ratio, 1 - self.clip_param, 1 + self.clip_param) * advantages
                actor_loss = -torch.min(surr1, surr2).mean()
                
                # ä»·å€¼æŸå¤±
                values_pred = self.critic(states).squeeze()
                critic_loss = F.mse_loss(values_pred, returns)
                
                # ç†µæŸå¤±
                entropy = entropies.mean()
                
                # æ€»æŸå¤±
                total_loss = actor_loss + self.value_loss_coef * critic_loss - self.entropy_coef * entropy
                
                # æ›´æ–°
                self.actor_optimizer.zero_grad()
                self.critic_optimizer.zero_grad()
                total_loss.backward()
                
                torch.nn.utils.clip_grad_norm_(self.actor.parameters(), self.max_grad_norm)
                torch.nn.utils.clip_grad_norm_(self.critic.parameters(), self.max_grad_norm)
                
                self.actor_optimizer.step()
                self.critic_optimizer.step()
                
                total_actor_loss += actor_loss.item()
                total_critic_loss += critic_loss.item()
                total_entropy += entropy.item()
        
        # æ¸…ç©ºç¼“å†²
        self.reset_buffer()
        
        return {
            'actor_loss': total_actor_loss / self.config['training']['ppo_epochs'],
            'critic_loss': total_critic_loss / self.config['training']['ppo_epochs'],
            'entropy': total_entropy / self.config['training']['ppo_epochs']
        }
    
    def _compute_gae(self):
        """è®¡ç®—GAE"""
        gamma = self.config['training']['gamma']
        gae_lambda = self.config['training']['gae_lambda']
        
        rewards = [np.mean(r) if len(r) > 0 else 0 for r in self.rewards]
        values = [v for v in self.values]
        dones = [d for d in self.dones]
        
        returns = np.zeros_like(rewards)
        advantages = np.zeros_like(rewards)
        
        gae = 0
        for step in reversed(range(len(rewards))):
            if step == len(rewards) - 1:
                next_value = 0
                next_non_terminal = 1.0 - dones[step]
            else:
                next_value = values[step + 1]
                next_non_terminal = 1.0 - dones[step]
            
            delta = rewards[step] + gamma * next_value * next_non_terminal - values[step]
            gae = delta + gamma * gae_lambda * next_non_terminal * gae
            
            advantages[step] = gae
            returns[step] = gae + values[step]
        
        return returns, advantages
    
    def _compute_action_probs(self, actions):
        """é‡æ–°è®¡ç®—åŠ¨ä½œæ¦‚ç‡"""
        try:
            # ç®€åŒ–ç‰ˆæœ¬ - å®é™…åº”ç”¨ä¸­éœ€è¦é‡æ–°å¤„ç†è§‚å¯Ÿ
            num_actions = len(actions)
            log_probs = torch.zeros_like(actions, dtype=torch.float32)
            entropies = torch.ones_like(actions, dtype=torch.float32) * 0.1
            
            return log_probs, entropies
        except:
            return None, None

# ============================================================================
# é…ç½®å’Œè¾…åŠ©å‡½æ•°
# ============================================================================

def create_magec_config():
    """åˆ›å»ºMAGECè®­ç»ƒé…ç½®"""
    return {
        'network': {
            'node_features': 4,
            'edge_features': 2,
            'gnn_hidden_size': 128,
            'gnn_layers': 10,
            'gnn_dropout': 0.1,
            'gnn_skip_connections': True,
            'critic_hidden_size': 512,
            'max_neighbors': 15
        },
        'training': {
            'num_episodes': 100,
            'episode_length': 200,
            'lr': 3e-4,
            'gamma': 0.99,
            'gae_lambda': 0.95,
            'clip_param': 0.2,
            'value_loss_coef': 1.0,
            'entropy_coef': 0.01,
            'max_grad_norm': 0.5,
            'ppo_epochs': 4,
            'batch_size': 64,
            'alpha': 1.0,
            'beta': 0.5
        },
        'system': {
            'device': 'cuda' if torch.cuda.is_available() else 'cpu',
            'seed': 42,
            'save_interval': 50
        }
    }

def get_global_state(env, observations, device):
    """æ„å»ºå…¨å±€çŠ¶æ€"""
    try:
        global_state = torch.zeros(env.num_nodes + env.num_agents, device=device)
        
        # èŠ‚ç‚¹é—²ç½®æ—¶é—´
        idleness_normalized = [env.node_idleness[i] / max(env.current_step + 1, 1) 
                              for i in range(env.num_nodes)]
        global_state[:env.num_nodes] = torch.tensor(idleness_normalized, dtype=torch.float32, device=device)
        
        # æ™ºèƒ½ä½“ä½ç½®
        for i, pos in enumerate(env.agent_positions):
            if i < env.num_agents:
                global_state[env.num_nodes + i] = pos / max(env.num_nodes, 1)
        
        return global_state
        
    except Exception as e:
        logger.warning(f"å…¨å±€çŠ¶æ€æ„å»ºå¤±è´¥: {e}")
        return torch.zeros(env.num_nodes + env.num_agents, device=device)

def save_model(actor, critic, optimizer_actor, optimizer_critic, config, 
               save_path, episode, performance_metrics=None):
    """ä¿å­˜æ¨¡å‹"""
    try:
        save_dir = os.path.dirname(save_path)
        if save_dir:
            os.makedirs(save_dir, exist_ok=True)
        
        checkpoint = {
            'episode': episode,
            'actor_state_dict': actor.state_dict(),
            'critic_state_dict': critic.state_dict(),
            'actor_optimizer_state_dict': optimizer_actor.state_dict(),
            'critic_optimizer_state_dict': optimizer_critic.state_dict(),
            'config': config,
            'performance_metrics': performance_metrics or {},
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
            'pytorch_version': torch.__version__
        }
        
        torch.save(checkpoint, save_path)
        logger.info(f"æ¨¡å‹å·²ä¿å­˜: {save_path}")
        return True
        
    except Exception as e:
        logger.error(f"æ¨¡å‹ä¿å­˜å¤±è´¥: {e}")
        return False

# ============================================================================
# äº¤äº’å¼è¾“å…¥
# ============================================================================

def interactive_input():
    """äº¤äº’å¼é…ç½®è¾“å…¥"""
    print("=" * 80)
    print("ğŸš€ MAGECè®­ç»ƒç³»ç»Ÿ - äº¤äº’å¼é…ç½®")
    print("=" * 80)
    print("ğŸ’¡ æç¤ºï¼šç›´æ¥æŒ‰å›è½¦ä½¿ç”¨é»˜è®¤å€¼")
    print()
    
    config = {}
    
    # 1. æ•°æ®æºé€‰æ‹©
    print("ğŸ“‚ æ•°æ®æºé€‰æ‹©")
    print("-" * 50)
    print("è¯·é€‰æ‹©æ•°æ®æºç±»å‹:")
    print("  1. è½½å…¥ç¯å¢ƒæ–‡ä»¶ï¼ˆå®Œæ•´ç¬¬ä¸€é˜¶æ®µï¼‰")
    print("  2. è½½å…¥æ‹“æ‰‘JSONï¼ˆç¬¬ä¸€é˜¶æ®µç»“æœï¼‰")
    print()
    
    while True:
        choice = input("è¯·é€‰æ‹© (1/2) [é»˜è®¤: 2]: ").strip()
        if not choice:
            choice = "2"
        
        if choice in ["1", "2"]:
            config['data_source'] = "environment" if choice == "1" else "topology_json"
            break
        else:
            print("âŒ è¯·è¾“å…¥1æˆ–2")
    
    # 2. è·¯å¾„è¾“å…¥
    print(f"\nğŸ“ {'ç¯å¢ƒæ–‡ä»¶' if config['data_source'] == 'environment' else 'æ‹“æ‰‘JSON'}è·¯å¾„é…ç½®")
    print("-" * 50)
    
    if config['data_source'] == "environment":
        # æœç´¢ç¯å¢ƒæ–‡ä»¶
        env_files = list(Path('.').glob('*.json'))
        env_files = [f for f in env_files if 'map' in f.name.lower() or 'env' in f.name.lower()]
        
        if env_files:
            print("ğŸ” å‘ç°ä»¥ä¸‹ç¯å¢ƒæ–‡ä»¶:")
            for i, file in enumerate(env_files, 1):
                print(f"  {i}. {file}")
            print()
            
            while True:
                file_choice = input("é€‰æ‹©æ–‡ä»¶ï¼ˆè¾“å…¥åºå·æˆ–å®Œæ•´è·¯å¾„ï¼‰[é»˜è®¤: 1]: ").strip()
                if not file_choice:
                    if env_files:
                        config['data_path'] = str(env_files[0])
                        break
                    else:
                        print("âŒ æœªæ‰¾åˆ°ç¯å¢ƒæ–‡ä»¶")
                        continue
                
                if file_choice.isdigit() and 1 <= int(file_choice) <= len(env_files):
                    config['data_path'] = str(env_files[int(file_choice) - 1])
                    break
                elif os.path.exists(file_choice):
                    config['data_path'] = file_choice
                    break
                else:
                    print("âŒ æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·é‡æ–°è¾“å…¥")
        else:
            while True:
                path = input("è¯·è¾“å…¥ç¯å¢ƒæ–‡ä»¶è·¯å¾„: ").strip()
                if path and os.path.exists(path):
                    config['data_path'] = path
                    break
                else:
                    print("âŒ æ–‡ä»¶ä¸å­˜åœ¨")
    
    else:  # topology_json
        # æœç´¢æ‹“æ‰‘æ–‡ä»¶
        topology_files = []
        for pattern in ['*topology*.json', '*complete_topology*.json', '*stage1*.json']:
            topology_files.extend(list(Path('.').glob(pattern)))
        
        # å»é‡å¹¶æŒ‰æ—¶é—´æ’åº
        topology_files = sorted(set(topology_files), key=lambda x: x.stat().st_mtime, reverse=True)
        
        if topology_files:
            print("ğŸ” å‘ç°ä»¥ä¸‹æ‹“æ‰‘æ–‡ä»¶:")
            for i, file in enumerate(topology_files[:5], 1):  # åªæ˜¾ç¤ºå‰5ä¸ª
                # æ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯
                try:
                    stat = os.stat(file)
                    mtime = time.strftime('%Y-%m-%d %H:%M', time.localtime(stat.st_mtime))
                    print(f"  {i}. {file.name}")
                    print(f"      ğŸ“… ä¿®æ”¹æ—¶é—´: {mtime}")
                except:
                    print(f"  {i}. {file}")
            print()
            
            while True:
                file_choice = input("é€‰æ‹©æ–‡ä»¶ï¼ˆè¾“å…¥åºå·æˆ–å®Œæ•´è·¯å¾„ï¼‰[é»˜è®¤: 1]: ").strip()
                if not file_choice:
                    if topology_files:
                        config['data_path'] = str(topology_files[0])
                        break
                    else:
                        print("âŒ æœªæ‰¾åˆ°æ‹“æ‰‘æ–‡ä»¶")
                        continue
                
                if file_choice.isdigit() and 1 <= int(file_choice) <= len(topology_files):
                    config['data_path'] = str(topology_files[int(file_choice) - 1])
                    break
                elif os.path.exists(file_choice):
                    config['data_path'] = file_choice
                    break
                else:
                    print("âŒ æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·é‡æ–°è¾“å…¥")
        else:
            while True:
                path = input("è¯·è¾“å…¥æ‹“æ‰‘JSONè·¯å¾„: ").strip()
                if path and os.path.exists(path):
                    config['data_path'] = path
                    break
                else:
                    print("âŒ æ–‡ä»¶ä¸å­˜åœ¨")
    
    print(f"âœ… å·²é€‰æ‹©: {config['data_path']}")
    print()
    
    # 3. è®­ç»ƒå‚æ•°
    print("âš™ï¸ è®­ç»ƒå‚æ•°é…ç½®")
    print("-" * 50)
    
    # æ™ºèƒ½ä½“æ•°é‡
    while True:
        agents_input = input("æ™ºèƒ½ä½“æ•°é‡ [é»˜è®¤: 4]: ").strip()
        if not agents_input:
            config['num_agents'] = 4
            break
        try:
            num_agents = int(agents_input)
            if 1 <= num_agents <= 8:
                config['num_agents'] = num_agents
                break
            else:
                print("âŒ æ™ºèƒ½ä½“æ•°é‡åº”åœ¨1-8ä¹‹é—´")
        except ValueError:
            print("âŒ è¯·è¾“å…¥æœ‰æ•ˆæ•°å­—")
    
    # è®­ç»ƒå›åˆæ•°
    while True:
        episodes_input = input("è®­ç»ƒå›åˆæ•° [é»˜è®¤: 100]: ").strip()
        if not episodes_input:
            config['num_episodes'] = 100
            break
        try:
            episodes = int(episodes_input)
            if episodes > 0:
                config['num_episodes'] = episodes
                break
            else:
                print("âŒ å›åˆæ•°å¿…é¡»å¤§äº0")
        except ValueError:
            print("âŒ è¯·è¾“å…¥æœ‰æ•ˆæ•°å­—")
    
    # æ¯å›åˆæ­¥æ•°
    while True:
        steps_input = input("æ¯å›åˆæ­¥æ•° [é»˜è®¤: 200]: ").strip()
        if not steps_input:
            config['episode_length'] = 200
            break
        try:
            steps = int(steps_input)
            if steps > 0:
                config['episode_length'] = steps
                break
            else:
                print("âŒ æ­¥æ•°å¿…é¡»å¤§äº0")
        except ValueError:
            print("âŒ è¯·è¾“å…¥æœ‰æ•ˆæ•°å­—")
    
    print(f"âœ… è®­ç»ƒå‚æ•°: {config['num_agents']}æ™ºèƒ½ä½“, {config['num_episodes']}å›åˆ, {config['episode_length']}æ­¥/å›åˆ")
    print()
    
    # 4. è¾“å‡ºé…ç½®
    print("ğŸ“ è¾“å‡ºé…ç½®")
    print("-" * 50)
    
    default_output = f"experiments/magec_training_{time.strftime('%Y%m%d_%H%M%S')}"
    output_dir = input(f"è¾“å‡ºç›®å½• [é»˜è®¤: {default_output}]: ").strip()
    config['output_dir'] = output_dir if output_dir else default_output
    
    # å¯è§†åŒ–é€‰é¡¹
    visualize = input("è®­ç»ƒå®Œæˆåæ˜¾ç¤ºæ‹“æ‰‘æ˜ å°„å›¾? (y/N) [é»˜è®¤: N]: ").strip().lower()
    config['show_topology'] = visualize in ['y', 'yes', '1', 'true']
    
    print(f"âœ… è¾“å‡ºç›®å½•: {config['output_dir']}")
    print()
    
    # æ˜¾ç¤ºæœ€ç»ˆé…ç½®
    print("ğŸ“‹ " + "=" * 76)
    print("ğŸ“‹ æœ€ç»ˆé…ç½®ç¡®è®¤")
    print("ğŸ“‹ " + "=" * 76)
    print(f"ğŸ”¹ æ•°æ®æº: {config['data_source']}")
    print(f"ğŸ”¹ æ•°æ®è·¯å¾„: {config['data_path']}")
    print(f"ğŸ”¹ æ™ºèƒ½ä½“æ•°é‡: {config['num_agents']}")
    print(f"ğŸ”¹ è®­ç»ƒå‚æ•°: {config['num_episodes']}å›åˆ Ã— {config['episode_length']}æ­¥")
    print(f"ğŸ”¹ è¾“å‡ºç›®å½•: {config['output_dir']}")
    print(f"ğŸ”¹ æ˜¾ç¤ºæ‹“æ‰‘å›¾: {'æ˜¯' if config['show_topology'] else 'å¦'}")
    print()
    
    confirm = input("ç¡®è®¤å¼€å§‹è®­ç»ƒ? (Y/n) [é»˜è®¤: Y]: ").strip().lower()
    if confirm in ['n', 'no', '0', 'false']:
        print("ğŸ‘‹ å·²å–æ¶ˆè®­ç»ƒ")
        sys.exit(0)
    
    return config

# ============================================================================
# ä¸»è®­ç»ƒå‡½æ•°
# ============================================================================

def train_magec(config):
    """MAGECè®­ç»ƒä¸»å‡½æ•°"""
    print(f"\nğŸ¯ å¼€å§‹MAGECè®­ç»ƒ")
    print("=" * 80)
    print(f"ğŸ“‚ æ•°æ®æº: {config['data_source']}")
    print(f"ğŸ“ æ•°æ®è·¯å¾„: {config['data_path']}")
    print(f"ğŸ¤– æ™ºèƒ½ä½“: {config['num_agents']}")
    print(f"ğŸƒ è®­ç»ƒ: {config['num_episodes']}å›åˆ Ã— {config['episode_length']}æ­¥")
    print(f"ğŸ’¾ è¾“å‡º: {config['output_dir']}")
    print("=" * 80)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(config['output_dir'], exist_ok=True)
    
    # è®¾å¤‡é…ç½®
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ”§ è®¾å¤‡: {device}")
    
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(42)
    np.random.seed(42)
    random.seed(42)
    
    try:
        # === 1. æ„å»ºç¯å¢ƒ ===
        print("\nğŸ”„ æ„å»ºè®­ç»ƒç¯å¢ƒ...")
        
        if config['data_source'] == 'environment':
            # ä»ç¯å¢ƒæ–‡ä»¶æ„å»ºï¼ˆå®Œæ•´æµç¨‹ï¼‰
            print("ä½¿ç”¨ç¯å¢ƒæ–‡ä»¶æ„å»º...")
            # TODO: å®ç°ç¯å¢ƒæ–‡ä»¶åŠ è½½
            print("âš ï¸ ç¯å¢ƒæ–‡ä»¶æ¨¡å¼å°šæœªå®ç°ï¼Œè¯·ä½¿ç”¨æ‹“æ‰‘JSONæ¨¡å¼")
            return
        
        else:  # topology_json
            # ä»æ‹“æ‰‘JSONæ„å»º
            mapper = TopologyToMAGECMapper()
            
            if not mapper.load_topology_from_json(config['data_path']):
                print("âŒ æ‹“æ‰‘åŠ è½½å¤±è´¥")
                return
            
            env_config = mapper.create_magec_environment(config['num_agents'])
            
            # å¯é€‰ï¼šæ˜¾ç¤ºæ‹“æ‰‘æ˜ å°„å›¾
            if config['show_topology']:
                print("ğŸ¨ ç”Ÿæˆæ‹“æ‰‘æ˜ å°„å›¾...")
                mapper.visualize_mapped_topology(f"{config['output_dir']}/topology_mapping.png")
        
        # åˆ›å»ºè®­ç»ƒç¯å¢ƒ
        env = MAGECTrainingEnvironment(env_config)
        print(f"âœ… è®­ç»ƒç¯å¢ƒåˆ›å»ºå®Œæˆ: {env.num_nodes}èŠ‚ç‚¹, {env.num_agents}æ™ºèƒ½ä½“")
        
        # === 2. åˆ›å»ºç½‘ç»œ ===
        print("\nğŸ”„ åˆ›å»ºMAGECç½‘ç»œ...")
        
        training_config = create_magec_config()
        training_config['training']['num_episodes'] = config['num_episodes']
        training_config['training']['episode_length'] = config['episode_length']
        training_config['network']['max_neighbors'] = env.max_neighbors
        
        # Actorç½‘ç»œ
        actor = MAGECActor(
            node_features=training_config['network']['node_features'],
            edge_features=training_config['network']['edge_features'],
            hidden_size=training_config['network']['gnn_hidden_size'],
            num_layers=training_config['network']['gnn_layers'],
            max_neighbors=env.max_neighbors,
            dropout=training_config['network']['gnn_dropout'],
            use_skip_connections=training_config['network']['gnn_skip_connections']
        ).to(device)
        
        # Criticç½‘ç»œ
        global_state_size = env.num_nodes + env.num_agents
        critic = MAGECCritic(
            global_state_size=global_state_size,
            hidden_size=training_config['network']['critic_hidden_size']
        ).to(device)
        
        print(f"ğŸ§  Actorå‚æ•°: {sum(p.numel() for p in actor.parameters()):,}")
        print(f"ğŸ§  Criticå‚æ•°: {sum(p.numel() for p in critic.parameters()):,}")
        
        # === 3. åˆ›å»ºè®­ç»ƒå™¨ ===
        trainer = MAGECTrainer(actor, critic, training_config, device)
        
        # === 4. è®­ç»ƒå¾ªç¯ ===
        print(f"\nğŸƒ å¼€å§‹è®­ç»ƒ...")
        
        episode_rewards = []
        episode_idleness = []
        training_losses = []
        
        with tqdm(total=config['num_episodes'], desc="è®­ç»ƒè¿›åº¦", unit="ep") as pbar:
            for episode in range(config['num_episodes']):
                # é‡ç½®ç¯å¢ƒ
                observations = env.reset()
                episode_reward = []
                
                for step in range(config['episode_length']):
                    # é€‰æ‹©åŠ¨ä½œ
                    actions, log_probs, entropies = trainer.select_actions(observations)
                    
                    # è·å–å…¨å±€çŠ¶æ€å’Œä»·å€¼
                    global_state = get_global_state(env, observations, device)
                    values = trainer.get_value(global_state)
                    
                    # æ‰§è¡ŒåŠ¨ä½œ
                    next_observations, rewards, done = env.step(actions)
                    
                    # å­˜å‚¨è½¬æ¢
                    trainer.store_transition(
                        observations, global_state, actions, rewards,
                        log_probs, values, done
                    )
                    
                    episode_reward.extend(rewards)
                    observations = next_observations
                    
                    if done:
                        break
                
                # æ›´æ–°ç½‘ç»œ
                losses = trainer.update()
                
                # è®°å½•æŒ‡æ ‡
                avg_reward = np.mean(episode_reward) if episode_reward else 0
                avg_idleness = np.mean(list(env.node_idleness.values()))
                
                episode_rewards.append(avg_reward)
                episode_idleness.append(avg_idleness)
                training_losses.append(losses)
                
                # æ›´æ–°è¿›åº¦æ¡
                pbar.set_postfix({
                    'Reward': f'{avg_reward:.3f}',
                    'Idleness': f'{avg_idleness:.1f}',
                    'A_Loss': f'{losses["actor_loss"]:.4f}',
                    'C_Loss': f'{losses["critic_loss"]:.4f}'
                })
                pbar.update(1)
                
                # å®šæœŸä¿å­˜
                if episode % 50 == 0 and episode > 0:
                    save_path = f"{config['output_dir']}/checkpoint_ep{episode}.pth"
                    save_model(actor, critic, trainer.actor_optimizer, 
                              trainer.critic_optimizer, training_config, save_path, episode)
        
        # === 5. ä¿å­˜æœ€ç»ˆæ¨¡å‹ ===
        print(f"\nğŸ’¾ ä¿å­˜è®­ç»ƒç»“æœ...")
        
        final_model_path = f"{config['output_dir']}/magec_final_model.pth"
        final_metrics = {
            'episode': config['num_episodes'],
            'final_avg_reward': np.mean(episode_rewards[-20:]) if len(episode_rewards) >= 20 else np.mean(episode_rewards),
            'final_avg_idleness': np.mean(episode_idleness[-20:]) if len(episode_idleness) >= 20 else np.mean(episode_idleness),
            'episode_rewards': episode_rewards,
            'episode_idleness': episode_idleness,
            'training_losses': training_losses,
            'env_config': env_config,
            'training_completed': True
        }
        
        success = save_model(actor, critic, trainer.actor_optimizer, 
                           trainer.critic_optimizer, training_config, 
                           final_model_path, config['num_episodes'], final_metrics)
        
        if success:
            print(f"âœ… æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜: {final_model_path}")
        
        # === 6. ç”Ÿæˆè®­ç»ƒæ›²çº¿ ===
        print(f"ğŸ“Š ç”Ÿæˆè®­ç»ƒæ›²çº¿...")
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        
        # å›åˆå¥–åŠ±
        episodes = range(len(episode_rewards))
        axes[0, 0].plot(episodes, episode_rewards, 'b-', alpha=0.7)
        if len(episode_rewards) > 10:
            smooth_rewards = np.convolve(episode_rewards, np.ones(10)/10, mode='valid')
            axes[0, 0].plot(range(9, len(episode_rewards)), smooth_rewards, 'r-', linewidth=2)
        axes[0, 0].set_title('Episode Rewards')
        axes[0, 0].set_xlabel('Episode')
        axes[0, 0].set_ylabel('Average Reward')
        axes[0, 0].grid(True, alpha=0.3)
        
        # å¹³å‡é—²ç½®æ—¶é—´
        axes[0, 1].plot(episodes, episode_idleness, 'g-', alpha=0.7)
        if len(episode_idleness) > 10:
            smooth_idleness = np.convolve(episode_idleness, np.ones(10)/10, mode='valid')
            axes[0, 1].plot(range(9, len(episode_idleness)), smooth_idleness, 'r-', linewidth=2)
        axes[0, 1].set_title('Average Idleness (Lower is Better)')
        axes[0, 1].set_xlabel('Episode')
        axes[0, 1].set_ylabel('Average Idleness')
        axes[0, 1].grid(True, alpha=0.3)
        
        # è®­ç»ƒæŸå¤±
        if training_losses:
            actor_losses = [loss['actor_loss'] for loss in training_losses]
            critic_losses = [loss['critic_loss'] for loss in training_losses]
            
            axes[1, 0].plot(actor_losses, 'orange', label='Actor Loss')
            axes[1, 0].plot(critic_losses, 'red', label='Critic Loss')
            axes[1, 0].set_title('Training Losses')
            axes[1, 0].set_xlabel('Episode')
            axes[1, 0].set_ylabel('Loss')
            axes[1, 0].legend()
            axes[1, 0].grid(True, alpha=0.3)
            axes[1, 0].set_yscale('log')
        
        # æ€§èƒ½æ‘˜è¦
        if final_metrics:
            summary_text = f"""è®­ç»ƒæ‘˜è¦:
â€¢ æœ€ç»ˆå¹³å‡å¥–åŠ±: {final_metrics['final_avg_reward']:.3f}
â€¢ æœ€ç»ˆå¹³å‡é—²ç½®: {final_metrics['final_avg_idleness']:.3f}
â€¢ æœ€ä½³å¥–åŠ±: {max(episode_rewards):.3f}
â€¢ æœ€ä½³é—²ç½®: {min(episode_idleness):.3f}

ç¯å¢ƒä¿¡æ¯:
â€¢ èŠ‚ç‚¹æ•°: {env.num_nodes}
â€¢ æ™ºèƒ½ä½“æ•°: {env.num_agents}
â€¢ æœ€å¤§é‚»å±…æ•°: {env.max_neighbors}
â€¢ è®­ç»ƒå›åˆ: {config['num_episodes']}"""
            
            axes[1, 1].text(0.05, 0.95, summary_text, transform=axes[1, 1].transAxes, 
                           fontsize=11, verticalalignment='top', fontfamily='monospace')
            axes[1, 1].set_title('Training Summary')
            axes[1, 1].axis('off')
        
        plt.tight_layout()
        
        curves_path = f"{config['output_dir']}/training_curves.png"
        plt.savefig(curves_path, dpi=150, bbox_inches='tight')
        plt.close()
        
        print(f"âœ… è®­ç»ƒæ›²çº¿å·²ä¿å­˜: {curves_path}")
        
        # === 7. ä¿å­˜è®­ç»ƒé…ç½® ===
        config_path = f"{config['output_dir']}/training_config.json"
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump({
                'input_config': config,
                'training_config': training_config,
                'final_metrics': final_metrics,
                'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
            }, f, indent=2, ensure_ascii=False, default=str)
        
        print(f"âœ… è®­ç»ƒé…ç½®å·²ä¿å­˜: {config_path}")
        
        # === 8. è®­ç»ƒå®Œæˆæ‘˜è¦ ===
        print(f"\nğŸ‰ MAGECè®­ç»ƒå®Œæˆ!")
        print("=" * 80)
        print(f"ğŸ“Š è®­ç»ƒç»Ÿè®¡:")
        print(f"   ğŸ¯ æœ€ç»ˆå¹³å‡å¥–åŠ±: {final_metrics['final_avg_reward']:.3f}")
        print(f"   â±ï¸  æœ€ç»ˆå¹³å‡é—²ç½®: {final_metrics['final_avg_idleness']:.3f}")
        print(f"   ğŸ† æœ€ä½³å¥–åŠ±: {max(episode_rewards):.3f}")
        print(f"   âš¡ æœ€ä½³é—²ç½®: {min(episode_idleness):.3f}")
        print(f"\nğŸ“ è¾“å‡ºæ–‡ä»¶:")
        print(f"   ğŸ¤– æœ€ç»ˆæ¨¡å‹: magec_final_model.pth")
        print(f"   ğŸ“ˆ è®­ç»ƒæ›²çº¿: training_curves.png")
        print(f"   âš™ï¸  è®­ç»ƒé…ç½®: training_config.json")
        if config['show_topology']:
            print(f"   ğŸ—ºï¸  æ‹“æ‰‘æ˜ å°„: topology_mapping.png")
        print(f"\nğŸ“‚ æ‰€æœ‰æ–‡ä»¶ä¿å­˜åœ¨: {config['output_dir']}/")
        print("=" * 80)
        print(f"ğŸ’¡ ç°åœ¨å¯ä»¥ä½¿ç”¨ visualize.py æ¥æµ‹è¯•å’Œå¯è§†åŒ–è®­ç»ƒç»“æœï¼")
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='MAGECè®­ç»ƒç³»ç»Ÿ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  python demo_MAGEC.py                           # äº¤äº’å¼æ¨¡å¼
  python demo_MAGEC.py --topology topology.json # æŒ‡å®šæ‹“æ‰‘æ–‡ä»¶
  python demo_MAGEC.py --env environment.json   # æŒ‡å®šç¯å¢ƒæ–‡ä»¶
        """
    )
    parser.add_argument('--topology', type=str, help='æ‹“æ‰‘JSONæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--env', type=str, help='ç¯å¢ƒæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--agents', type=int, default=4, help='æ™ºèƒ½ä½“æ•°é‡')
    parser.add_argument('--episodes', type=int, default=100, help='è®­ç»ƒå›åˆæ•°')
    parser.add_argument('--episode_length', type=int, default=200, help='æ¯å›åˆæ­¥æ•°')
    parser.add_argument('--output_dir', type=str, help='è¾“å‡ºç›®å½•')
    parser.add_argument('--show_topology', action='store_true', help='æ˜¾ç¤ºæ‹“æ‰‘æ˜ å°„å›¾')
    parser.add_argument('--batch', action='store_true', help='æ‰¹å¤„ç†æ¨¡å¼ï¼ˆéäº¤äº’ï¼‰')
    
    args = parser.parse_args()
    
    # å†³å®šä½¿ç”¨äº¤äº’å¼è¿˜æ˜¯å‘½ä»¤è¡Œæ¨¡å¼
    if args.batch and (args.topology or args.env):
        # æ‰¹å¤„ç†æ¨¡å¼
        config = {
            'data_source': 'topology_json' if args.topology else 'environment',
            'data_path': args.topology or args.env,
            'num_agents': args.agents,
            'num_episodes': args.episodes,
            'episode_length': args.episode_length,
            'output_dir': args.output_dir or f"experiments/magec_training_{time.strftime('%Y%m%d_%H%M%S')}",
            'show_topology': args.show_topology
        }
        
        print("ğŸ¤– æ‰¹å¤„ç†æ¨¡å¼")
        
    elif args.topology or args.env:
        # ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°ä½†ä¿æŒéƒ¨åˆ†äº¤äº’
        config = {
            'data_source': 'topology_json' if args.topology else 'environment',
            'data_path': args.topology or args.env,
            'num_agents': args.agents,
            'num_episodes': args.episodes,
            'episode_length': args.episode_length,
            'output_dir': args.output_dir or f"experiments/magec_training_{time.strftime('%Y%m%d_%H%M%S')}",
            'show_topology': args.show_topology
        }
        
        print("ğŸ”§ å‘½ä»¤è¡Œæ¨¡å¼")
        
    else:
        # äº¤äº’å¼æ¨¡å¼
        config = interactive_input()
    
    # å¼€å§‹è®­ç»ƒ
    train_magec(config)

if __name__ == "__main__":
    main()